{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import zip_longest\n",
    "from math import ceil\n",
    "import datetime as dt\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from typing import Optional, List, Dict, Iterable, Tuple\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "import numpy as np\n",
    "import praw\n",
    "from psaw import PushshiftAPI\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO list:\n",
    "\n",
    "1. Get all flaired submissions in a week\n",
    "2. Check for duplicates (once)\n",
    "3. Parse the response, get id, use PRAW to get post info\n",
    "4. Filter by flair\n",
    "5. Run over various weeks, combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunker(seq: Iterable, size: int) -> Iterable:\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reddit = praw.Reddit(client_id='TiogCJcLNTKaXQ', \n",
    "#                      client_secret='vtroPTNpBpqh2Qze5umXTlpmh7A', \n",
    "#                      username='Moral_Judgement_Bot', \n",
    "#                      password='A not very secure password.',\n",
    "#                      user_agent='AITA bot test script')\n",
    "\n",
    "# api = PushshiftAPI(r=reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posts_between(start: int, end: int, field_names: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    if field_names is None:\n",
    "        field_names = ['id']#, 'title', 'selftext', 'score', 'author']\n",
    "\n",
    "    # TODO: can be optimized by avoiding pandas\n",
    "    api_url = 'https://api.pushshift.io/reddit/submission/search'\n",
    "\n",
    "    req = requests.get(api_url, \n",
    "            params = {\n",
    "                \"subreddit\": \"AmITheAsshole\",\n",
    "                \"sort\": \"desc\",\n",
    "                \"sort_type\": \"score\",\n",
    "                \"after\": start,\n",
    "                \"before\": end,\n",
    "                \"limit\": 10000\n",
    "            })\n",
    "    \n",
    "    res = json.loads(req.content)\n",
    "    \n",
    "    filtered = filter(\n",
    "            lambda x: all(name in x.keys() for name in field_names),\n",
    "            res['data']\n",
    "            )\n",
    "\n",
    "    data = list(map(\n",
    "                lambda x: tuple(x[field] for field in field_names), \n",
    "                filtered\n",
    "                ))\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=field_names)\n",
    "    df['name'] = 't3_' + df['id']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_info(names: List[str], useragent: str = 'MoralJudgementIncoming') -> List[Dict]:\n",
    "    all_names = ','.join(names)\n",
    "    \n",
    "    res = requests.get('https://www.reddit.com/api/info.json',\n",
    "            params={'id': all_names},\n",
    "            headers={'User-agent': useragent})\n",
    "    \n",
    "    posts_info = json.loads(res.content)['data']['children']\n",
    "    \n",
    "#     print(len(posts_info), len(names))\n",
    "    assert len(posts_info) == len(names), ValueError(\"Didn't get all posts' info\")\n",
    "    \n",
    "    return posts_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_details(names: Iterable[str]) -> pd.DataFrame:\n",
    "    \n",
    "    # TODO: add error handling if a chunk fails\n",
    "    chunk_size = 100\n",
    "    \n",
    "    name_chunks = chunker(names, chunk_size)\n",
    "\n",
    "    all_info = []\n",
    "    \n",
    "    chunk_count = ceil(len(names) / chunk_size)\n",
    "\n",
    "    for chunk in tqdm(name_chunks, total=chunk_count):\n",
    "        info = request_info(chunk)\n",
    "\n",
    "        all_info.extend(info)\n",
    "\n",
    "\n",
    "    field_names = ['id', 'title', 'created', 'selftext', 'score', 'edited', 'link_flair_text']\n",
    "\n",
    "    data = list(map(\n",
    "                lambda x: (x['data'][field] for field in field_names), \n",
    "                all_info\n",
    "                ))\n",
    "\n",
    "    df_new = pd.DataFrame(data, columns=field_names)\n",
    "    df_new = df_new.fillna('')\n",
    "    df_new = df_new.set_index('id')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_days(start: Tuple[int], end: Tuple[int], diff: int = 24, finer_start: Optional[Tuple[int]] = None) -> Tuple[dt.datetime, dt.datetime]:\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        start: (year, month, day), start date\n",
    "        end: (year, month, day), end date\n",
    "        diff: number of hours to iterate over\n",
    "        finer_start: (year, month, day), optional time to reduce the diff by half, for better granularity\n",
    "    \"\"\" # TODO: somehow make it possible to change timedelta maybe\n",
    "    start_dt = dt.datetime(*start)\n",
    "    end_dt = dt.datetime(*end)\n",
    "    \n",
    "    assert start_dt < end_dt, ValueError(\"Start date should be before end date\")\n",
    "    \n",
    "    current_dt = dt.datetime(*start)\n",
    "    \n",
    "    \n",
    "    if finer_start is None:\n",
    "        finer = True\n",
    "        finer_dt = None\n",
    "    else:\n",
    "        finer = False\n",
    "        finer_dt = dt.datetime(*finer_start)\n",
    "    \n",
    "    while current_dt != end_dt:\n",
    "        start = current_dt\n",
    "        end = current_dt + dt.timedelta(hours=diff)\n",
    "        \n",
    "        # If we're not in fine mode yet, and we passed a certain date, decrease the diff\n",
    "\n",
    "        if not finer and current_dt >= finer_dt:\n",
    "            finer = True\n",
    "            diff = diff // 2\n",
    "        \n",
    "        current_dt = end\n",
    "        yield int(start.timestamp()), int(end.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data(start: Tuple[int], \n",
    "                 end: Tuple[int], \n",
    "                 diff: int = 24, \n",
    "                 finer_start: Optional[Tuple[int]] = None,\n",
    "                 save_names: Optional[str] = None, \n",
    "                 save_data: Optional[str] = None) -> pd.DataFrame:\n",
    "    \n",
    "    days = iterate_days(start, end, diff, finer_start)\n",
    "\n",
    "    df_list = []\n",
    "\n",
    "    num_days = (dt.datetime(*end) - dt.datetime(*start)).days\n",
    "    \n",
    "    if finer_start is not None:\n",
    "        num_days += (dt.datetime(*end) - dt.datetime(*finer_start)).days\n",
    "\n",
    "    print(\"Downloading post names from pushshift API\")\n",
    "    \n",
    "    for start, end in tqdm(days, total=num_days):\n",
    "        df_part = get_posts_between(start=start, end=end)\n",
    "        df_list.append(df_part)\n",
    "\n",
    "#     plt.plot(list(map(lambda x: x.name.shape[0], df_list)))\n",
    "\n",
    "    all_names = np.concatenate(list(map(lambda df: df.name.values, df_list)))\n",
    "\n",
    "    if save_names is not None:\n",
    "        with open(save_names, 'w') as f:\n",
    "            for name in all_names:\n",
    "                f.write(name)\n",
    "\n",
    "    print(\"Downloading post details from reddit API\")\n",
    "    \n",
    "    df_full = get_details(all_names)\n",
    "\n",
    "    if save_data is not None:\n",
    "        df_full.to_csv(save_data)\n",
    "        \n",
    "    return df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/464 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading post names from pushshift API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 463/464 [13:05<00:01,  1.70s/it]\n",
      "  0%|          | 0/2082 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading post details from reddit API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2082/2082 [43:55<00:00,  1.27s/it]\n"
     ]
    }
   ],
   "source": [
    "df_full = get_all_data(start = (2018, 9, 1),\n",
    "                       end = (2019, 8, 20), \n",
    "                       diff = 24,\n",
    "                       finer_start = (2019, 5, 1), \n",
    "                       save_names = 'new_names.txt',\n",
    "                       save_data = 'new_data.csv'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full = pd.read_csv('all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_full[~df_full['selftext'].isin(['[removed]', '[deleted]'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83840, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = list(map(lambda x: len(x), df_filtered.selftext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(list(map(lambda x: len(x), df_filtered.selftext)), bins=500)\n",
    "plt.xlim((0, 5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_filtered.groupby('link_flair_text').count()[['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link_flair_text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asshole</th>\n",
       "      <td>16956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Everyone Sucks</th>\n",
       "      <td>5378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No A-holes here</th>\n",
       "      <td>10994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not enough info</th>\n",
       "      <td>2243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not the A-hole</th>\n",
       "      <td>46133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shitpost</th>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TL;DR</th>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asshole</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not the a-hole</th>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title\n",
       "link_flair_text       \n",
       "                   409\n",
       "Asshole          16956\n",
       "Everyone Sucks    5378\n",
       "No A-holes here  10994\n",
       "Not enough info   2243\n",
       "Not the A-hole   46133\n",
       "Shitpost           228\n",
       "TL;DR              181\n",
       "asshole            204\n",
       "not the a-hole     622"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[counts > 100].dropna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df_filtered[df_filtered['link_flair_text'].isin(['Asshole', 'Everyone Sucks', 'Not the A-hole', 'No A-holes here'])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AssholeBot",
   "language": "python",
   "name": "aita"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
